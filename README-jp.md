# LLMクライアント - 複数AIプロバイダー対応

[한국어](README-ko.md) | [日本語](README-jp.md) | [English](README.md)

MyOllama3は、SwiftUIで開発されたiOSアプリケーションで、Ollamaサーバー、LMStudio、Claude API、OpenAI APIなど複数のAIプロバイダーに接続して対話型AIチャットボット機能を提供します。

![poster](./captures.jpg)

## 🎁 アプリダウンロード

- ビルドが困難な方は、下記のリンクからアプリをダウンロードできます。
- [https://apps.apple.com/us/app/llm-client-for-ollama/id6738298481](https://apps.apple.com/us/app/llm-client-for-ollama/id6738298481)

## 📱 プロジェクト概要

このアプリは、**プライバシー保護**と**柔軟性**を重視するユーザーのために設計された**統合AI会話アプリケーション**です。複数の大規模言語モデル（LLM）プロバイダーと相互作用できる直感的なインターフェースを提供し、すべての会話内容はユーザーのデバイスにのみ安全に保存されます。

## ✨ コア機能

### 🤖 マルチプロバイダーAIサポート
- **Ollama統合**: ローカルまたはリモートOllamaサーバーへの接続
- **LMStudio互換性**: LMStudioローカル推論サーバーのサポート
- **Claude API**: AnthropicのClaudeモデルとの直接統合
- **OpenAI API**: OpenAI APIを通じたGPTモデルのサポート
- **動的切り替え**: 会話中のプロバイダー間のシームレスな切り替え
- **プロバイダー記憶**: 最後に使用したLLMプロバイダーとモデルの自動記憶

### 🔄 強化されたユーザーエクスペリエンス
- **リアルタイムモデル更新**: プロバイダー切り替え時に利用可能モデルの自動更新
- **永続的な選択**: アプリ起動時に最後に使用したLLMとモデルの自動復元
- **動的構成**: アプリ再起動なしですべての設定をリアルタイム適用
- **接続状況**: サーバー/API接続状況のリアルタイム監視
- **柔軟なURL処理**: 空/無効なURLに対する優雅なエラー処理

### 🤖 AI会話機能
- **リアルタイムストリーミング応答**: ストリーミングサポートによる高速リアルタイムAI応答
- **マルチモデルサポート**: サポートされたプロバイダーのすべてのAIモデル（Llama、Mistral、Qwen、GPT、Claudeなど）
- **マルチモーダル会話**: ビジョンモデルによる画像添付と画像分析のサポート
- **ドキュメント処理**: PDFおよびテキストファイルのアップロードと分析機能
- **ファイル添付サポート**: 画像（JPG、PNG、GIFなど）、PDFドキュメント、テキストファイルなど様々なファイル形式のサポート
- **応答キャンセル**: AI応答生成をいつでも中断可能
- **自動画像リサイズ**: 最適なパフォーマンスのための自動画像圧縮とリサイズ

### 📚 会話管理
- **永続ストレージ**: SQLiteデータベースを使用したすべての会話履歴の自動保存
- **会話検索**: キーワードベースの会話内容検索機能
- **会話復元**: 以前の会話の読み込みとシームレスな継続
- **プロバイダー別管理**: 異なるAIプロバイダーとの会話の個別管理
- **メッセージ管理**: コンテキストメニューによる個別メッセージのコピー、共有、削除
- **会話全体エクスポート**: 外部使用のための会話全体のテキストエクスポート
- **会話削除**: 確認付きの完全な会話削除

### ⚙️ 高度な設定
- **マルチプロバイダー構成**: Ollama、LMStudio、Claude、OpenAIの個別管理
- **APIキー管理**: ClaudeおよびOpenAI APIキーの安全な保存と管理
- **AIパラメータ調整**: Temperature（0.1-2.0）、Top P（0.1-1.0）、Top K（1-100）の微調整
- **カスタム指示**: AI動作カスタマイズのためのシステムプロンプト設定
- **接続テスト**: すべてのサポートされたプロバイダーに対する内蔵接続テスト
- **設定永続性**: すべての設定の自動保存と復元
- **リアルタイム設定適用**: アプリ再起動なしで設定変更の即座適用
- **データ管理**: 確認付きの完全な会話データ削除

### 🌍 ユーザーエクスペリエンス
- **多言語サポート**: 韓国語、英語、日本語の完全ローカライゼーション
- **ダークモードサポート**: システムテーマに応じた自動カラー適応
- **直感的UI**: メッセージバブル、コンテキストメニュー、ハプティックフィードバック、レスポンシブデザイン
- **アクセシビリティ**: VoiceOverとアクセシビリティ機能のサポート
- **カメラ統合**: 画像キャプチャと分析のための直接カメラアクセス
- **ドキュメントピッカー**: ネイティブiOSドキュメントピッカーの統合
- **タッチジェスチャー**: メッセージアクションのための長押し、キーボード解除のためのタップ
- **ローディング状態**: すべての非同期操作に対する視覚的フィードバック

### 📎 ファイル・メディアサポート
- **画像形式**: JPG、JPEG、PNG、GIF、BMP、TIFF、HEIC、WebP
- **ドキュメント形式**: PDF（テキスト抽出付き）、TXT、RTF、プレーンテキスト
- **画像処理**: 自動圧縮とBase64エンコーディング
- **PDFテキスト抽出**: PDFドキュメントからの完全テキスト抽出
- **ファイルプレビュー**: 送信前の添付ファイルの視覚的プレビュー
- **マルチフォーマット処理**: インテリジェントなファイルタイプ検出と処理

## 🏗️ アーキテクチャ構造

```
myollama3/
├── 📱 UI Views
│   ├── ContentView.swift          # メイン画面（会話リストと新規会話）
│   ├── ChatView.swift            # チャットインターフェース（リアルタイム会話）
│   ├── SettingsView.swift        # マルチプロバイダー設定画面
│   ├── WelcomeView.swift         # オンボーディング画面（初回起動ガイド）
│   └── AboutView.swift           # アプリ情報と使用ガイド
│
├── 🧩 Components
│   ├── MessageBubble.swift       # メッセージバブルUI（マークダウンレンダリング）
│   ├── MessageInputView.swift    # 動的モデル読み込み付き拡張入力
│   ├── DocumentPicker.swift      # ドキュメント選択と処理
│   ├── CameraPicker.swift        # カメラ統合コンポーネント
│   └── ShareSheet.swift          # ネイティブ共有機能
│
├── ⚙️ Services
│   ├── swift_llm_bridge.swift   # 統合マルチプロバイダーLLM通信
│   └── DatabaseService.swift    # SQLiteデータベース管理
│
├── 🔧 Utils & Extensions
│   ├── AppColor.swift           # 適応カラーテーマ管理
│   ├── ImagePicker.swift        # カメラ/ギャラリー画像選択
│   ├── Localized.swift          # 多言語文字列拡張
│   ├── KeyboardExtensions.swift # キーボード管理ユーティリティ
│   └── SettingsManager.swift    # 集中設定と永続化管理
│
└── 🌍 Localization
    ├── ko.lproj/                # 韓国語（デフォルト）
    ├── en.lproj/                # 英語
    └── ja.lproj/                # 日本語
```

### 🔧 主要アーキテクチャ変更

#### 動的構成システム
- **静的構成削除**: ハードコードされたサーバー設定の削除
- **UserDefaults統合**: すべての構成を永続ストレージから動的に読み取り
- **リアルタイム更新**: アプリ再起動なしで設定変更の即座適用
- **プロバイダー切り替え**: 異なるAIプロバイダー間のシームレス切り替え

#### 拡張LLMブリッジ
- **マルチプロバイダーサポート**: すべてのサポートされたAIプロバイダーのための単一統合インターフェース
- **動的ベースURL**: 空文字列サポートによる柔軟なURL処理
- **プロバイダー検出**: 自動プロバイダー識別と適切なAPI処理
- **永続状態**: 最後に使用したプロバイダーとモデルの自動復元

## 🚀 使用方法

### 1. 初期セットアップ

#### Ollama/LMStudio（ローカルサーバー）用
1. **サーバー準備**: OllamaまたはLMStudioサーバーをローカルまたはネットワークで実行
2. **初回アプリ起動**: スタート画面でサーバーセットアップガイドを確認
3. **サーバーアドレス入力**: 設定 → LLMサーバーに移動してURL入力（例：`http://192.168.0.1:11434`）
4. **プロバイダー有効化**: OllamaサーバーまたはLMStudioをトグルオン
5. **接続テスト**: 「サーバー接続状態確認」ボタンで接続テスト

#### Claude/OpenAI（APIサービス）用
1. **APIキー取得**: AnthropicまたはOpenAIからAPIキーを取得
2. **プロバイダー有効化**: 設定 → Claude APIまたはOpenAI APIをトグルオン
3. **APIキー入力**: 該当フィールドにAPIキーを入力
4. **パラメータ構成**: 必要に応じてTemperature、Top P、Top K値を調整

### 2. 会話開始
1. **新規会話**: メイン画面で「新規会話開始」ボタンをタッチ
2. **プロバイダー選択**: ドロップダウンからAIプロバイダーを選択（Ollama、LMStudio、Claude、またはOpenAI）
3. **モデル選択**: 選択したプロバイダーに応じて利用可能モデルが自動更新
4. **メッセージ入力**: 下部入力フィールドに質問や指示を入力
5. **ファイル添付**: クリップアイコンを使用して画像、PDF、テキストファイルを追加（サポートされている場合）
6. **メッセージ送信**: 矢印ボタンまたはEnterキーで送信

### 2.1. プロバイダー別機能
- **Ollama/LMStudio**: ローカル処理による完全なマルチモーダルサポート
- **Claude**: 画像分析機能を持つ高度な推論
- **OpenAI**: 包括的な機能サポートを持つGPTモデル
- **自動復元**: アプリ再起動時に最後に使用したプロバイダーとモデルの自動復元

## 🔧 プロバイダーセットアップガイド

### Ollamaサーバーセットアップ
#### ローカルサーバー（macOS/Linux）
```bash
# Ollama インストール
curl -fsSL https://ollama.ai/install.sh | sh

# サーバー開始（外部アクセス許可）
OLLAMA_HOST=0.0.0.0:11434 ollama serve

# モデルダウンロード例
ollama pull llama2
ollama pull mistral
ollama pull qwen
ollama pull llava              # 画像分析用
ollama pull codellama         # コードサポート用
```

#### ネットワーク構成
- **ファイアウォール**: ポート11434を開放
- **ルーター**: 必要に応じてポートフォワーディング設定
- **IPアドレス**: アプリ設定に正しいサーバーIPを入力
- **接続テスト**: 内蔵接続テスト機能を使用

### LMStudioセットアップ
1. **LMStudioダウンロード**: [https://lmstudio.ai](https://lmstudio.ai)からインストール
2. **モデル読み込み**: お好みのモデルをダウンロード＆読み込み
3. **サーバー開始**: ローカルサーバーを有効化（デフォルトポート：1234）
4. **アプリ構成**: アプリ設定にLMStudioサーバーURLを入力

### Claude APIセットアップ
1. **APIキー取得**: [https://console.anthropic.com](https://console.anthropic.com)でサインアップ
2. **APIキー生成**: アカウント設定でAPIキー生成
3. **アプリ構成**: 設定 → Claude APIにAPIキーを入力
4. **プロバイダー有効化**: アプリでClaude APIをトグルオン

### OpenAI APIセットアップ
1. **APIキー取得**: [https://platform.openai.com](https://platform.openai.com)でサインアップ
2. **APIキー生成**: アカウントでAPIキーを生成
3. **アプリ構成**: 設定 → OpenAI APIにAPIキーを入力
4. **プロバイダー有効化**: アプリでOpenAI APIをトグルオン

## 🚀 サポートモデル

### Ollamaモデル
Ollamaを通じて利用可能なすべてのモデルがサポートされています：
- **Llama 2/3**: 優秀なパフォーマンスの一般会話モデル
- **Mistral**: 多言語サポートを持つ高性能会話モデル
- **Qwen**: 強力な推論能力を持つ高度な多言語サポートモデル
- **Gemma**: Googleの軽量で効率的なモデル
- **CodeLlama**: プログラミングと開発サポート
- **DeepSeek-Coder**: 複数言語をサポートする高度コーディング専門家
- **LLaVA**: 画像認識と視覚分析モデル
- **Bakllava**: 複雑な視覚タスクのための高度ビジョン言語モデル

### LMStudioモデル
LMStudioのOpenAI互換APIと互換性のあるすべてのモデル：
- **量子化モデル**: 様々な量子化レベルのGGUFフォーマットモデル
- **ローカルモデル**: ローカルで実行されるダウンロードモデル
- **カスタムモデル**: ユーザーがインポートしたモデルとファインチューンバージョン

### Claudeモデル（Anthropic）
- **Claude 3 Haiku**: 日常的なタスクのための高速で効率的なモデル
- **Claude 3 Sonnet**: ほとんどのユースケースのためのバランス取れたパフォーマンス
- **Claude 3 Opus**: 複雑なタスクのための最も能力のあるモデル
- **Claude 3.5 Sonnet**: 改善された機能を持つ最新モデル

### OpenAIモデル
- **GPT-4**: ビジョン機能を持つ最新マルチモーダルモデル
- **GPT-4 Turbo**: より大きなコンテキストウィンドウを持つ最適化バージョン
- **GPT-3.5 Turbo**: 高速でコスト効率的なモデル
- **カスタムモデル**: アカウントで利用可能なファインチューンモデル

## 🔐 プライバシー保護

MyOllama3はユーザープライバシーを優先します：

- ✅ **ローカルストレージ**: すべての会話内容をユーザーデバイスにのみ保存
- ✅ **外部送信なし**: 構成されたプロバイダーサーバー以外にはデータ送信なし
- ✅ **ローカルAI処理**: すべてのAI処理がローカルサーバーで実行（Ollama/LMStudioの場合）
- ✅ **ファイルセキュリティ**: スコープ付きリソースアクセスによる安全なファイル処理
- ✅ **暗号化**: SQLiteデータベースのデフォルトセキュリティ適用
- ✅ **トラッキングなし**: ユーザー行動追跡や分析データ収集なし
- ✅ **データ制御**: データ削除に対する完全なユーザー制御

## 📋 システム要件

- **iOS**: 16.0以上
- **Xcode**: 15.0以上（開発用）
- **Swift**: 5.9以上
- **ネットワーク**: ローカルネットワークまたはリモートサーバーで実行されるプロバイダーサーバー/API
- **ストレージ**: 最小100MB（会話履歴と添付ファイルに応じた追加スペース）
- **メモリ**: 画像処理とPDFテキスト抽出のための十分なRAM

---

**MyOllama3で高度なファイルサポートを持つ安全でプライベートなAI会話を体験してください！🚀** 